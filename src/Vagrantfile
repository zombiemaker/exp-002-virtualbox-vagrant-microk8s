# https://www.vagrantup.com/docs/vagrantfile/

# This is just a Ruby program:  https://www.ruby-lang.org/en/documentation/
# When creating VirtualBox VMs using Vagrant, Vagrant creates a file system mount /vagrant
# that is linked to the VM host machine's directory where the vagrant program was executed.
# This enables the VM guest OS to access and share files between VMs

debug = false
deploy_elb = false
deploy_edns = false
deploy_k8s_master = true
deploy_k8s_worker = false

# Assuming that a cluster is needed for a separate geographic region  or availability zone
# Each cluster needs:
#   - External BGP router / load balancer
#   - External DNS server
#   - External TLS certificate authority
#   - Kubernetes master nodes
#   - Kubernetes worker nodes

regions = ["us-east"]  # ["us-east", "us-west", "eu-east", etc....]
number_of_regions = regions.size
number_of_elbs_per_region = 1
number_of_ednss_per_region = 1
number_of_clusters_per_region = 1
number_of_clusters = number_of_regions * number_of_clusters_per_region
number_of_azs_per_region = 3

# Master nodes and worker nodes will be in the same subnet
# Total number of master and worker nodes cannot exceed subnet capacity (including addresses reserved for network services)
# Distribute nodes across number of AZs
# Each K8s cluster will use 1 IPv4 class C address range (for this design)
# Estimate 100 pods per worker node
master_nodes_per_cluster = 3
worker_nodes_per_cluster = 1
number_ip_addresses_reserved_per_cluster = 5


Vagrant.require_version ">= 1.3.5"
Vagrant.configure("2") do |config|

    # Configurations for all VMs
    # Enable SSH authentication using username and password
    config.vm.provision "shell", inline: <<-EOF
        echo "Changing sshd configuration to allow username and password authentication"
        sudo sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_config

        echo "Restarting sshd process"
        sudo systemctl restart sshd
    EOF


    # VM specific configurations
    (1..number_of_regions).each do |r|

        # ELBs and DNSs are region level components
        if deploy_elb
            (1..number_of_elbs_per_region).each do |elb_id|
                # Cluster BGP Router / External Load Balancer (assuming 2 ELBs per cluster)
                
                config.vm.define("k8s-r#{r}-elb#{elb_id}") do |elb|
                    elb.vm.box = "ubuntu/focal64"
                    elb.vm.hostname = "k8s-r#{r}-elb#{elb_id}"
                    elb.vm.network("private_network", ip: "10.#{r}.0.#{elb_id}", netmask: "255.255.255.0")
                    elb.vm.provider("virtualbox") do |vb|
                        vb.gui = true
                        vb.name = "k8s-r#{r}-elb#{elb_id}"
                        vb.memory = 2048
                        vb.cpus = 1            
                    end # vb

                    elb.vm.disk(:disk, size: "70GB", primary: true)

                    elb.vm.provision "shell", inline: <<-EOF
                        echo Configuring k8s-r#{r}-elb#{elb_id}"
                        sudo apt update && apt upgrade -y
                        sudo apt install quagga-bgpd quagga-doc -y
                    EOF
                end # elb config.vm.define
            end # elb_id
        end # if deploy_elb

        # Cluster External DNS Authoritative Servers
        if deploy_edns
            (1..number_of_ednss_per_region).each do |edns_id|
                config.vm.define("k8s-r#{r}-edns#{edns_id}") do |edns|
                    edns.vm.box = "ubuntu/focal64"
                    edns.vm.hostname = "k8s-r#{r}-edns#{edns_id}"
                    edns.vm.network("private_network", ip: "10.#{r}.0.#{number_of_elbs_per_region + edns_id}", netmask: "255.255.255.0")
                    edns.vm.provider("virtualbox") do |vb|
                        vb.gui = true
                        vb.name = "k8s-r#{r}-edns#{edns_id}"
                        vb.memory = 2048
                        vb.cpus = 1            
                    end # vb

                    edns.vm.disk(:disk, size: "20GB", primary: true)

                    edns.vm.provision "shell", inline: <<-EOF
                        echo Configuring k8s-r#{r}-edns#{edns_id}
                        sudo apt update && apt upgrade -y
                    EOF
                end # edns config.vm.define
            end # edns_id
        end # if deploy_edns


        (1..number_of_clusters_per_region).each do |c|
            # Kubernetes Cluster Master Nodes
            if deploy_k8s_master
                (1..master_nodes_per_cluster).each do |m|
                    # Define local variable to point cluster main master node
                    $master_node_m1 = nil
                    $master_node_m1_vm_hostname = nil
                    $master_node_m1_vm_ipv4_address = nil

                    config.vm.define("k8s-r#{r}-c#{c}-m#{m}") do |master_node|
                        master_node_vm_name = "k8s-r#{r}-c#{c}-m#{m}"
                        master_node_vm_hostname = "k8s-r#{r}-c#{c}-m#{m}"
                        master_node_vm_ipv4_address = "10.#{r}.#{c}.#{m + number_ip_addresses_reserved_per_cluster}"
                        
                        if m == 1
                            $master_node_m1 = master_node
                            $master_node_m1_vm_hostname = master_node_vm_hostname
                            $master_node_m1_vm_ipv4_address = master_node_vm_ipv4_address
                        end # if m == 1

                        master_node.vm.box = "ubuntu/focal64"
                        master_node.vm.hostname = $master_node_vm_hostname
                        
                        if debug
                            puts "Current master_node object id = #{master_node.object_id}"
                            puts "Current master_node.vm = #{master_node.vm}"
                            puts "master_node_m1 object id = #{$master_node_m1.object_id}"
                            puts "master_node_m1.vm = #{$master_node_m1.vm}"
                        end # if debug
                        
                        # IPv4 addresses allocated from start of address range after reserved addresses
                        master_node.vm.network("private_network", ip: master_node_vm_ipv4_address, netmask: "255.255.255.0")
                        master_node.vm.provider("virtualbox") do |vb|
                            vb.gui = true
                            vb.name = master_node_vm_name
                            vb.memory = 4096
                            vb.cpus = 2            
                        end #vb

                        master_node.vm.disk(:disk, size: "40GB", primary: true)

                        master_node.vm.provision "shell", inline: <<-EOF
                            echo "Configuring $(hostname)"
                            echo "master_node_m1_vm_ipv4_address = #{$master_node_m1_vm_ipv4_address}"
                            
                            # Update and upgrade apt packages
                            sudo apt update && apt upgrade -y
                            
                            # Update snap packages
                            sudo snap refresh
                            
                            # Install MicroK8s snap package
                            sudo snap install microk8s --classic

                            # Add user vagrant to user group microk8s
                            sudo usermod -a -G microk8s vagrant
                            
                            # Check if MicroK8s is running - wait until process is ready
                            microk8s status --wait-ready
                            microk8s kubectl cluster-info
                            
                            # Install kubectl snap package
                            sudo snap install kubectl --classic

                            # Configure kubectl
                            cd ~
                            echo "Current working directory: $(pwd)"
                            cd .kube

                            # TODO: this is not going to have the right IP address to the API server - it will use the adapter connected to the NAT
                            microk8s config > /vagrant/kubectl-config
                            sudo sed -i 's+server: https://10.0.2.15:16443+https://10.1.1.6:16443+g' /vagrant/kubectl-config
                            whoami
                            pwd
                            cp /vagrant/kubectl-config ~/.kube/config
                        EOF

                        if m != 1
                            # Generate node token on main master node                            
                            $master_node_m1.vm.provision "shell", inline: <<-EOF
                                echo "Generating MicroK8s new node token for #{master_node_vm_hostname}"
                                microk8s add-node | grep #{$master_node_m1_vm_ipv4_address} | tee /vagrant/add_k8s_node_#{master_node_vm_hostname}
                            EOF

                            # Join cluster on new node using generated token
                            master_node.vm.provision "shell", inline: <<-EOF
                                echo "Joining MicroK8s cluster using new node token"
                                bash -x /vagrant/add_k8s_node_#{master_node_vm_hostname}
                            EOF
                        end # if m != 1
                    end # master_node config.vm.define
                end # m
            end # if deploy_k8s_master

            # Kubernetes Cluster Worker Nodes
            if deploy_k8s_worker
                (1..worker_nodes_per_cluster).each do |w|
                    config.vm.define("k8s-r#{r}-c#{c}-w#{w}") do |worker_node|
                        worker_node.vm.box = "ubuntu/focal64"
                        worker_node.vm.hostname = "k8s-r#{r}-c#{c}-w#{w}"

                        # IPv4 addresses allocated from end of address range
                        worker_node.vm.network("private_network", ip: "10.#{r}.#{c}.#{255-w}", netmask: "255.255.255.0")
                        worker_node.vm.provider("virtualbox") do |vb|
                            vb.gui = true
                            vb.name = "k8s-r#{r}-c#{c}-w#{w}"
                            vb.memory = 4096
                            vb.cpus = 2            
                        end # vb

                        worker_node.vm.disk(:disk, size: "70GB", primary: true)

                        worker_node.vm.provision("shell") do |s|
                            s.inline = "echo Configuring k8s-r#{r}-c#{c}-w#{w}"
                        end # s
                    end # worker_node config.vm.define
                end # w
            end # if deploy_k8s_worker
        end # c
    end # r
end # config
